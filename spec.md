# ML Performance Models Survey

## Goal

Write a paper for **MICRO 2026** that provides a systematic review of high-level ML performance models and simulators, **including third-party evaluation of key solutions**.

## Long-Term Vision

Beyond the survey paper, explore creating a unified performance modeling tool that combines the best approaches from literatureâ€”a practical contribution for the community.

## Milestones

### M1: Literature Discovery (Target: Week 2) âœ… COMPLETE
- Identify relevant papers on ML performance models and simulators
- Create a structured bibliography database
- Categorize papers by approach (analytical, simulation, hybrid, ML-based)

### M2: Taxonomy Development (Target: Week 4) âœ… COMPLETE
- Define classification dimensions (accuracy, speed, target hardware, etc.)
- Create comparison framework
- Draft taxonomy section of paper

### M3: Deep Analysis (Target: Week 8) âœ… COMPLETE
- Detailed review of key papers in each category
- Extract methodology patterns
- Identify gaps and opportunities

### M4: Paper Draft (Target: Week 12) ðŸ”„ IN PROGRESS
- Complete first draft of all sections
- Generate comparison tables and figures
- Internal review and revision

### M5: Experimental Evaluation (Target: Week 14) ðŸ†•
- Select 3-5 most important/reproducible solutions from literature
- Execute and evaluate on common workloads
- Document accuracy, speed, and usability findings
- Add empirical comparison section to paper

### M6: Submission Ready (Target: Week 18)
- Final polishing and formatting
- Incorporate experimental results
- Camera-ready submission to MICRO 2026

### M7: Unified Tool Exploration (Post-Submission) ðŸ†•
- Analyze feasibility of combining approaches
- Prototype unified performance modeling API
- If viable, develop open-source tool for community

## Current Status

**Active Milestone:** M4 - Paper Draft (Sections 5-7 in review)
